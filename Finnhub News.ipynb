{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqQCqE-c-sGc"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PskG05TlIa1W",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.37-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.10/site-packages (from yfinance) (1.26.3)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.31.0)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting lxml>=4.9.1 (from yfinance)\n",
      "  Downloading lxml-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in /opt/conda/lib/python3.10/site-packages (from yfinance) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2022.5 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2023.3.post1)\n",
      "Collecting frozendict>=2.3.4 (from yfinance)\n",
      "  Downloading frozendict-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.17.1.tar.gz (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.11.1 in /opt/conda/lib/python3.10/site-packages (from yfinance) (4.12.2)\n",
      "Collecting html5lib>=1.1 (from yfinance)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2023.11.17)\n",
      "Downloading yfinance-0.2.37-py2.py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.0/73.0 kB\u001b[0m \u001b[31m304.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozendict-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.7/116.7 kB\u001b[0m \u001b[31m238.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m393.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lxml-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m126.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Building wheels for collected packages: peewee\n",
      "  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peewee: filename=peewee-3.17.1-cp310-cp310-linux_x86_64.whl size=273724 sha256=ff50842926f9940b4a56d3ca8300fa1377b85174b20cc10cd683d1e40a841ce3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vo9be486/wheels/d7/35/5c/1374782be033462df5f40174d8d879519d64ed8c25a1977554\n",
      "Successfully built peewee\n",
      "Installing collected packages: peewee, multitasking, lxml, html5lib, frozendict, yfinance\n",
      "Successfully installed frozendict-2.4.0 html5lib-1.1 lxml-5.1.0 multitasking-0.0.11 peewee-3.17.1 yfinance-0.2.37\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting finnhub-python\n",
      "  Downloading finnhub_python-2.4.19-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: requests>=2.22.0 in /opt/conda/lib/python3.10/site-packages (from finnhub-python) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.22.0->finnhub-python) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.22.0->finnhub-python) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.22.0->finnhub-python) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.22.0->finnhub-python) (2023.11.17)\n",
      "Downloading finnhub_python-2.4.19-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: finnhub-python\n",
      "Successfully installed finnhub-python-2.4.19\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting news-please\n",
      "  Downloading news_please-1.5.44-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting Scrapy>=1.1.0 (from news-please)\n",
      "  Downloading Scrapy-2.11.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting PyMySQL>=0.7.9 (from news-please)\n",
      "  Downloading PyMySQL-1.1.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting psycopg2-binary>=2.8.4 (from news-please)\n",
      "  Downloading psycopg2_binary-2.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting hjson>=1.5.8 (from news-please)\n",
      "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting elasticsearch>=2.4 (from news-please)\n",
      "  Downloading elasticsearch-8.12.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.3.2 in /opt/conda/lib/python3.10/site-packages (from news-please) (4.12.2)\n",
      "Collecting readability-lxml>=0.6.2 (from news-please)\n",
      "  Downloading readability_lxml-0.8.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting newspaper3k>=0.2.8 (from news-please)\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting langdetect>=1.0.7 (from news-please)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from news-please) (2.8.2)\n",
      "Collecting plac>=0.9.6 (from news-please)\n",
      "  Downloading plac-1.4.3-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting dotmap>=1.2.17 (from news-please)\n",
      "  Downloading dotmap-1.3.30-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting PyDispatcher>=2.0.5 (from news-please)\n",
      "  Downloading PyDispatcher-2.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting warcio>=1.3.3 (from news-please)\n",
      "  Downloading warcio-1.7.4-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Collecting ago>=0.0.9 (from news-please)\n",
      "  Downloading ago-0.0.95.tar.gz (4.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from news-please) (1.16.0)\n",
      "Requirement already satisfied: lxml>=3.3.5 in /opt/conda/lib/python3.10/site-packages (from news-please) (5.1.0)\n",
      "Collecting hurry.filesize>=0.9 (from news-please)\n",
      "  Downloading hurry.filesize-0.9.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bs4 (from news-please)\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting faust-cchardet>=2.1.18 (from news-please)\n",
      "  Downloading faust_cchardet-2.1.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
      "Collecting boto3 (from news-please)\n",
      "  Downloading boto3-1.34.54-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4>=4.3.2->news-please) (2.5)\n",
      "Collecting elastic-transport<9,>=8 (from elasticsearch>=2.4->news-please)\n",
      "  Downloading elastic_transport-8.12.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from hurry.filesize>=0.9->news-please) (68.2.2)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from newspaper3k>=0.2.8->news-please) (10.0.1)\n",
      "Requirement already satisfied: PyYAML>=3.11 in /opt/conda/lib/python3.10/site-packages (from newspaper3k>=0.2.8->news-please) (6.0.1)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k>=0.2.8->news-please)\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting nltk>=3.2.1 (from newspaper3k>=0.2.8->news-please)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: requests>=2.10.0 in /opt/conda/lib/python3.10/site-packages (from newspaper3k>=0.2.8->news-please) (2.31.0)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k>=0.2.8->news-please)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k>=0.2.8->news-please)\n",
      "  Downloading tldextract-5.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k>=0.2.8->news-please)\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jieba3k>=0.35.1 (from newspaper3k>=0.2.8->news-please)\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tinysegmenter==0.3 (from newspaper3k>=0.2.8->news-please)\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: chardet in /opt/conda/lib/python3.10/site-packages (from readability-lxml>=0.6.2->news-please) (4.0.0)\n",
      "Collecting Twisted>=18.9.0 (from Scrapy>=1.1.0->news-please)\n",
      "  Downloading twisted-24.3.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from Scrapy>=1.1.0->news-please) (41.0.7)\n",
      "Collecting itemloaders>=1.0.1 (from Scrapy>=1.1.0->news-please)\n",
      "  Downloading itemloaders-1.1.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting parsel>=1.5.0 (from Scrapy>=1.1.0->news-please)\n",
      "  Downloading parsel-1.8.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in /opt/conda/lib/python3.10/site-packages (from Scrapy>=1.1.0->news-please) (23.2.0)\n",
      "Collecting queuelib>=1.4.2 (from Scrapy>=1.1.0->news-please)\n",
      "  Downloading queuelib-1.6.2-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting service-identity>=18.1.0 (from Scrapy>=1.1.0->news-please)\n",
      "  Downloading service_identity-24.1.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting w3lib>=1.17.0 (from Scrapy>=1.1.0->news-please)\n",
      "  Downloading w3lib-2.1.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting zope.interface>=5.1.0 (from Scrapy>=1.1.0->news-please)\n",
      "  Downloading zope.interface-6.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protego>=0.1.15 (from Scrapy>=1.1.0->news-please)\n",
      "  Downloading Protego-0.3.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting itemadapter>=0.1.0 (from Scrapy>=1.1.0->news-please)\n",
      "  Downloading itemadapter-0.8.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from Scrapy>=1.1.0->news-please) (23.1)\n",
      "Collecting botocore<1.35.0,>=1.34.54 (from boto3->news-please)\n",
      "  Downloading botocore-1.34.54-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->news-please)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->news-please)\n",
      "  Downloading s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.54->boto3->news-please) (1.26.18)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->Scrapy>=1.1.0->news-please) (1.16.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from elastic-transport<9,>=8->elasticsearch>=2.4->news-please) (2023.11.17)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k>=0.2.8->news-please)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>=3.2.1->newspaper3k>=0.2.8->news-please) (8.1.7)\n",
      "Collecting joblib (from nltk>=3.2.1->newspaper3k>=0.2.8->news-please)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk>=3.2.1->newspaper3k>=0.2.8->news-please) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk>=3.2.1->newspaper3k>=0.2.8->news-please) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.10.0->newspaper3k>=0.2.8->news-please) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.10.0->newspaper3k>=0.2.8->news-please) (3.4)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/conda/lib/python3.10/site-packages (from service-identity>=18.1.0->Scrapy>=1.1.0->news-please) (23.1.0)\n",
      "Collecting pyasn1 (from service-identity>=18.1.0->Scrapy>=1.1.0->news-please)\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyasn1-modules (from service-identity>=18.1.0->Scrapy>=1.1.0->news-please)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k>=0.2.8->news-please)\n",
      "  Downloading requests_file-2.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /opt/conda/lib/python3.10/site-packages (from tldextract>=2.0.1->newspaper3k>=0.2.8->news-please) (3.13.1)\n",
      "Collecting automat>=0.8.0 (from Twisted>=18.9.0->Scrapy>=1.1.0->news-please)\n",
      "  Downloading Automat-22.10.0-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting constantly>=15.1 (from Twisted>=18.9.0->Scrapy>=1.1.0->news-please)\n",
      "  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting hyperlink>=17.1.1 (from Twisted>=18.9.0->Scrapy>=1.1.0->news-please)\n",
      "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting incremental>=22.10.0 (from Twisted>=18.9.0->Scrapy>=1.1.0->news-please)\n",
      "  Downloading incremental-22.10.0-py2.py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from Twisted>=18.9.0->Scrapy>=1.1.0->news-please) (4.9.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->Scrapy>=1.1.0->news-please) (2.21)\n",
      "Downloading news_please-1.5.44-py3-none-any.whl (90 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.3/90.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dotmap-1.3.30-py3-none-any.whl (11 kB)\n",
      "Downloading elasticsearch-8.12.1-py3-none-any.whl (432 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m432.1/432.1 kB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading faust_cchardet-2.1.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading plac-1.4.3-py2.py3-none-any.whl (22 kB)\n",
      "Downloading psycopg2_binary-2.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
      "Downloading PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading readability_lxml-0.8.1-py3-none-any.whl (20 kB)\n",
      "Downloading Scrapy-2.11.1-py2.py3-none-any.whl (287 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.8/287.8 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading warcio-1.7.4-py2.py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.34.54-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading botocore-1.34.54-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading elastic_transport-8.12.0-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading itemadapter-0.8.0-py3-none-any.whl (11 kB)\n",
      "Downloading itemloaders-1.1.0-py3-none-any.whl (11 kB)\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading parsel-1.8.1-py2.py3-none-any.whl (17 kB)\n",
      "Downloading Protego-0.3.0-py2.py3-none-any.whl (8.5 kB)\n",
      "Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
      "Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading service_identity-24.1.0-py3-none-any.whl (12 kB)\n",
      "Downloading tldextract-5.1.1-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading twisted-24.3.0-py3-none-any.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
      "Downloading zope.interface-6.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.3/247.3 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
      "Downloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
      "Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
      "Downloading requests_file-2.0.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: ago, hurry.filesize, langdetect, tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
      "  Building wheel for ago (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ago: filename=ago-0.0.95-py3-none-any.whl size=5160 sha256=c3614ebd4a923024e4884c20acf15233118eabe08b0e0c6728f29cb4c2d390d0\n",
      "  Stored in directory: /root/.cache/pip/wheels/a8/b3/4b/1a778dcc4ab767ee37335851d6df8922cf08cc8c67e3daf8f8\n",
      "  Building wheel for hurry.filesize (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hurry.filesize: filename=hurry.filesize-0.9-py3-none-any.whl size=4120 sha256=7200ca3643bbfa9cee8e56a8051b6a50c4b0497c6c46faa189f569f781cdfee4\n",
      "  Stored in directory: /root/.cache/pip/wheels/e9/af/17/1c4cd045d88f20d450522470819d85349c3388c151af64590b\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=e18f11ad2e30f85e0ac2cbcd08c6c258de2b3f1b174f116ee7b5adcbccf334ee\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13541 sha256=d0c32dd0f3ea156a5c4ecc9a880006e62c43cc3a2defe51c87ea63ddcf1a5256\n",
      "  Stored in directory: /root/.cache/pip/wheels/c8/d6/6c/384f58df48c00b9a31d638005143b5b3ac62c3d25fb1447f23\n",
      "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3339 sha256=4e54862ea59c02e163d51613bb2d6e1f8ab168ac22c7d64fd0528482de39a39c\n",
      "  Stored in directory: /root/.cache/pip/wheels/97/02/e7/a1ff1760e12bdbaab0ac824fae5c1bc933e41c4ccd6a8f8edb\n",
      "  Building wheel for jieba3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398380 sha256=28d1fd00e443a9333eb648f7054a8a3a27cbd45c584cc763f3352110a963a587\n",
      "  Stored in directory: /root/.cache/pip/wheels/7a/c4/0c/12a9a314ecac499456c4c3b2fcc2f635a3b45a39dfbd240299\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=ed5687cb66c84fde151096f4f6fd1e291160fe74785fa608e08ffb9b59e85f92\n",
      "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
      "Successfully built ago hurry.filesize langdetect tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
      "Installing collected packages: tinysegmenter, sgmllib3k, PyDispatcher, plac, jieba3k, incremental, hjson, faust-cchardet, dotmap, ago, zope.interface, warcio, w3lib, queuelib, PyMySQL, pyasn1, psycopg2-binary, protego, langdetect, joblib, jmespath, itemadapter, hyperlink, hurry.filesize, feedparser, elastic-transport, cssselect, constantly, automat, Twisted, requests-file, readability-lxml, pyasn1-modules, parsel, nltk, feedfinder2, elasticsearch, bs4, botocore, tldextract, service-identity, s3transfer, itemloaders, Scrapy, newspaper3k, boto3, news-please\n",
      "Successfully installed PyDispatcher-2.0.7 PyMySQL-1.1.0 Scrapy-2.11.1 Twisted-24.3.0 ago-0.0.95 automat-22.10.0 boto3-1.34.54 botocore-1.34.54 bs4-0.0.2 constantly-23.10.4 cssselect-1.2.0 dotmap-1.3.30 elastic-transport-8.12.0 elasticsearch-8.12.1 faust-cchardet-2.1.19 feedfinder2-0.0.4 feedparser-6.0.11 hjson-3.1.0 hurry.filesize-0.9 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.8.0 itemloaders-1.1.0 jieba3k-0.35.1 jmespath-1.0.1 joblib-1.3.2 langdetect-1.0.9 news-please-1.5.44 newspaper3k-0.2.8 nltk-3.8.1 parsel-1.8.1 plac-1.4.3 protego-0.3.0 psycopg2-binary-2.9.9 pyasn1-0.5.1 pyasn1-modules-0.3.0 queuelib-1.6.2 readability-lxml-0.8.1 requests-file-2.0.0 s3transfer-0.10.0 service-identity-24.1.0 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.1.1 w3lib-2.1.2 warcio-1.7.4 zope.interface-6.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.2.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.38.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.65.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.27.2)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.21.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2023.12.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.27.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.21.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.12.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.2)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.42.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.12.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pynvml\n",
      "  Downloading pynvml-11.5.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pynvml\n",
      "Successfully installed pynvml-11.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: paramiko in /opt/conda/lib/python3.10/site-packages (3.4.0)\n",
      "Requirement already satisfied: bcrypt>=3.2 in /opt/conda/lib/python3.10/site-packages (from paramiko) (4.1.2)\n",
      "Requirement already satisfied: cryptography>=3.3 in /opt/conda/lib/python3.10/site-packages (from paramiko) (41.0.7)\n",
      "Requirement already satisfied: pynacl>=1.5 in /opt/conda/lib/python3.10/site-packages (from paramiko) (1.5.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=3.3->paramiko) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko) (2.21)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scp in /opt/conda/lib/python3.10/site-packages (0.14.5)\n",
      "Requirement already satisfied: paramiko in /opt/conda/lib/python3.10/site-packages (from scp) (3.4.0)\n",
      "Requirement already satisfied: bcrypt>=3.2 in /opt/conda/lib/python3.10/site-packages (from paramiko->scp) (4.1.2)\n",
      "Requirement already satisfied: cryptography>=3.3 in /opt/conda/lib/python3.10/site-packages (from paramiko->scp) (41.0.7)\n",
      "Requirement already satisfied: pynacl>=1.5 in /opt/conda/lib/python3.10/site-packages (from paramiko->scp) (1.5.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=3.3->paramiko->scp) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko->scp) (2.21)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install yfinance --upgrade --no-cache-dir\n",
    "!pip install finnhub-python\n",
    "!pip3 install news-please\n",
    "\n",
    "!pip install torch\n",
    "!pip install peft\n",
    "!pip install -U accelerate\n",
    "!pip install transformers bitsandbytes\n",
    "!pip install pynvml\n",
    "!pip install nltk\n",
    "!pip install paramiko\n",
    "!pip install scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !find / -type f -exec du -h {} + | sort -rh | head -n 10\n",
    "!rm -rf /root/.cache/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paramiko\n",
    "from scp import SCPClient\n",
    "server = 'sshhop.hopto.org'\n",
    "port = 22\n",
    "user = 'mum'\n",
    "password = '1234'\n",
    "\n",
    "def create_ssh_client():\n",
    "    client = paramiko.SSHClient()\n",
    "    client.load_system_host_keys()\n",
    "    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    client.connect(server, port, user, password)\n",
    "    return client\n",
    "\n",
    "def upload_files(ssh_client, local_path, remote_path):\n",
    "    with SCPClient(ssh_client.get_transport()) as scp:\n",
    "        scp.put(local_path, remote_path)  # Use put for uploading\n",
    "\n",
    "def append_file(ssh_client, local_path, remote_path, temp_path=''):\n",
    "    \n",
    "        # Check if temp_path is empty\n",
    "    if not temp_path:\n",
    "        temp_path = remote_path + '.tmp'\n",
    "\n",
    "    upload_files(ssh_client, local_path, temp_path)\n",
    "\n",
    "    # Step 2: Append the content of the temporary file to the target file\n",
    "    temp_path = temp_path.replace(\"/\", \"\\\\\")\n",
    "    remote_path = remote_path.replace(\"/\", \"\\\\\")\n",
    "    command = f'type {temp_path} >> {remote_path} & del {temp_path}'\n",
    "    stdin, stdout, stderr = ssh_client.exec_command(command)\n",
    "    exit_status = stdout.channel.recv_exit_status()  # Wait for the command to complete\n",
    "    \n",
    "    # Reading the output of the command\n",
    "    output = stdout.read().decode('utf-8')\n",
    "    error = stderr.read().decode('utf-8')\n",
    "\n",
    "    # Check if command was successful\n",
    "    if exit_status == 0:\n",
    "        print(\"Command executed successfully\")\n",
    "    else:\n",
    "        print(f\"Command failed with exit status {exit_status}\")\n",
    "\n",
    "    # Optional: Print the outputs for debugging or logging\n",
    "    if output:\n",
    "        print(\"Output:\", output)\n",
    "        \n",
    "    if error:\n",
    "        print(\"Error:\", error)\n",
    "\n",
    "    return not exit_status\n",
    "\n",
    "def download_files(ssh_client, remote_path, local_path):\n",
    "    print(\"downloading\")\n",
    "    with SCPClient(ssh_client.get_transport()) as scp:\n",
    "        scp.get(remote_path, local_path)\n",
    "    print(\"done downloading\")\n",
    "\n",
    "# Optional: Execute a command or run a script on the remote machine\n",
    "# stdin, stdout, stderr = ssh_client.exec_command('python /path/to/remote/script.py')\n",
    "# print(stdout.read().decode())  # Assuming the script has output\n",
    "\n",
    "def close_client(ssh_client):\n",
    "    # Close the SSH connection\n",
    "    ssh_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['test test.', 'test.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "\n",
    "def rank_sentences(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_frequencies = defaultdict(int)\n",
    "    \n",
    "    # Tokenize words and count frequencies, ignoring stopwords\n",
    "    for word in word_tokenize(text):\n",
    "        if word.lower() not in stop_words:\n",
    "            word_frequencies[word.lower()] += 1\n",
    "    \n",
    "    # Ensure word_frequencies is not empty before finding the max frequency\n",
    "    if word_frequencies:\n",
    "        max_frequency = max(word_frequencies.values())\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "    # Normalize frequencies\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] = (word_frequencies[word] / max_frequency)\n",
    "    \n",
    "    sentence_scores = defaultdict(int)\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Score sentences by summing normalized frequencies of their words\n",
    "    for sent in sentences:\n",
    "        for word in word_tokenize(sent.lower()):\n",
    "            if word in word_frequencies:\n",
    "                sentence_scores[sent] += word_frequencies[word]\n",
    "    \n",
    "    # Get top n sentences based on their scores\n",
    "    summary_sentences = heapq.nlargest(3, sentence_scores, key=sentence_scores.get)\n",
    "    return summary_sentences\n",
    "\n",
    "rank_sentences(\"test. test test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2hMNfEgCn-X"
   },
   "source": [
    "**FinForcaster App.py**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rKZwbTC3W9S6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import finnhub\n",
    "import torch\n",
    "# import gradio as gr\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pynvml import *\n",
    "from peft import PeftModel\n",
    "from collections import defaultdict\n",
    "from datetime import date, datetime, timedelta\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "\n",
    "finnhub_client = finnhub.Client(api_key=\"cmr6gghr01qvmr5q06u0cmr6gghr01qvmr5q06ug\")\n",
    "\n",
    "def print_gpu_utilization():\n",
    "\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "def get_curday():\n",
    "\n",
    "    return datetime.today().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "\n",
    "def n_weeks_before(date_string, n):\n",
    "    # date = datetime.strptime(date_string, \"%Y-%m-%d_%H-%M\") - timedelta(days=7*n)\n",
    "    thedate = datetime.strptime(date_string, \"%Y-%m-%d_%H-%M\") - timedelta(days=n)\n",
    "    return thedate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def n_days_before(date_string, n):\n",
    "    thedate = datetime.strptime(date_string, \"%Y-%m-%d_%H-%M\") - timedelta(days=n)\n",
    "    return thedate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def get_stock_data(stock_symbol, steps):\n",
    "\n",
    "    stock_data = yf.download(stock_symbol, steps[0], steps[-1])\n",
    "    if len(stock_data) == 0:\n",
    "        raise gr.Error(f\"Failed to download stock price data for symbol {stock_symbol} from yfinance!\")\n",
    "\n",
    "#     print(stock_data)\n",
    "\n",
    "    dates, prices = [], []\n",
    "    available_dates = stock_data.index.format()\n",
    "\n",
    "    for date in steps[:-1]:\n",
    "        for i in range(len(stock_data)):\n",
    "            if available_dates[i] >= date:\n",
    "                prices.append(stock_data['Close'][i])\n",
    "                dates.append(datetime.strptime(available_dates[i], \"%Y-%m-%d\"))\n",
    "                break\n",
    "\n",
    "    dates.append(datetime.strptime(available_dates[-1], \"%Y-%m-%d\"))\n",
    "    prices.append(stock_data['Close'][-1])\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"Start Date\": dates[:-1], \"End Date\": dates[1:],\n",
    "        \"Start Price\": prices[:-1], \"End Price\": prices[1:]\n",
    "    })\n",
    "\n",
    "from dateutil.parser import parse\n",
    "from zoneinfo import ZoneInfo\n",
    "def get_news_local(symbol, data, profile, past_hours):\n",
    "    file_path = f'{symbol}_news.jsonl'\n",
    "    def download_news():\n",
    "        ssh_client = create_ssh_client()\n",
    "        download_files(ssh_client, f'/C:/Users/mum/Documents/news_aggregation_ipynb/news/{file_path}', f'{file_path}')\n",
    "        close_client(ssh_client)   \n",
    "    download_news()\n",
    "\n",
    "    recent_news = []    \n",
    "    # Calculate 24 hours ago from now\n",
    "    twenty_four_hours_ago = datetime.now(ZoneInfo(\"UTC\")) - timedelta(hours=past_hours)\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            article = json.loads(line)\n",
    "                # raise Exception(f\"No company news found for symbol {symbol} from local!\")\n",
    "            \n",
    "            # Convert published date from the provided format\n",
    "            article_date = parse(article.get(\"published date\"))\n",
    "\n",
    "            # Check if the article's content is not None and the article is within the last 24 hours\n",
    "            if article.get('content') and article_date > twenty_four_hours_ago:\n",
    "                # print(rank_sentences(article['content'])[:2])\n",
    "                summary_sentences = ' '.join(rank_sentences(article['content'])[:2])\n",
    "                recent_news.append({\n",
    "                    \"date\": article_date.strftime('%Y-%m-%d %H:%M'),\n",
    "                    \"headline\": article.get('title'),\n",
    "                    \"summary\": summary_sentences,\n",
    "                    \"url\": article.get('url'),\n",
    "                    \"source\": article.get(article['publisher']['title'])\n",
    "                })\n",
    "                \n",
    "        if len(recent_news) == 0:\n",
    "            print(\"NO NEWS TO EVALUATE!\")\n",
    "\n",
    "    news_list = []\n",
    "    news_list.append(json.dumps(recent_news))\n",
    "    data['News'] = json.dumps(recent_news)\n",
    "    \n",
    "    print(\"Number of news items: \", len(recent_news)) \n",
    "    # print(recent_news)\n",
    "    print(data['News'])\n",
    "    return data\n",
    "\n",
    "def get_news(symbol, data, profile):\n",
    "    \n",
    "    news_list = []\n",
    "    filtered_company_name = ' '.join(profile['name'].split()[:1])\n",
    "    print(profile)\n",
    "\n",
    "    for end_date, row in data.iterrows():\n",
    "        print(\"asdfghjkl\")\n",
    "        start_date = row['Start Date'].strftime('%Y-%m-%d')\n",
    "        end_date = row['End Date'].strftime('%Y-%m-%d')\n",
    "#         print(symbol, ': ', start_date, ' - ', end_date)\n",
    "        # time.sleep(1) # control qpm\n",
    "        weekly_news = finnhub_client.company_news(symbol, _from=start_date, to=end_date)\n",
    "        if len(weekly_news) == 0:\n",
    "            raise gr.Error(f\"No company news found for symbol {symbol} from finnhub!\")\n",
    "        weekly_news = [\n",
    "            {\n",
    "                \"date\": datetime.fromtimestamp(n['datetime']).strftime('%Y-%m-%d %H:%M'),\n",
    "                \"headline\": n['headline'],\n",
    "                \"summary\": n['summary'],\n",
    "                \"url\": n['url'],\n",
    "                \"source\": n['source']\n",
    "            } \n",
    "            for n in weekly_news\n",
    "            if \"zacks.com\" not in n['summary'].lower() and \n",
    "               (symbol.lower() in n['headline'].lower() or filtered_company_name.lower() in n['headline'].lower())\n",
    "        ]\n",
    "        weekly_news.sort(key=lambda x: x['date'])\n",
    "        news_list.append(json.dumps(weekly_news))\n",
    "\n",
    "    data['News'] = news_list\n",
    "    print(data['News'])\n",
    "\n",
    "    # additions:\n",
    "    total_news_count = sum(len(json.loads(weekly_news)) for weekly_news in news_list)\n",
    "    print(\"Number of news items after filtering: \", total_news_count) \n",
    "\n",
    "    # To save the news to a file, use:\n",
    "    print_or_save_news(data['News'], f\"{symbol}_news.txt\")\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_or_save_news(news_list, filename=None):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"\")\n",
    "    for news_items_str in news_list:\n",
    "        news_items = json.loads(news_items_str)  # Load the JSON string into a list of dictionaries\n",
    "        for news in news_items:\n",
    "            news_str = f\"Date: {news['date']}\\nHeadline: {news['headline']}\\nSummary: {news['summary']}\\nURL: {news['url']}\\nSource: {news['source']}\\n\\n\"\n",
    "            if filename:\n",
    "                with open(filename, 'a', encoding='utf-8') as file:\n",
    "                    file.write(news_str)\n",
    "            else:\n",
    "                print(news_str)\n",
    "\n",
    "def get_company_prompt(symbol, profile):\n",
    "\n",
    "    # profile = finnhub_client.company_profile2(symbol=symbol)\n",
    "    if not profile:\n",
    "        raise gr.Error(f\"Failed to find company profile for symbol {symbol} from finnhub!\")\n",
    "\n",
    "    company_template = \"[Company Introduction]:\\n\\n{name} is a leading entity in the {finnhubIndustry} sector. Incorporated and publicly traded since {ipo}, the company has established its reputation as one of the key players in the market. As of today, {name} has a market capitalization of {marketCapitalization:.2f} in {currency}, with {shareOutstanding:.2f} shares outstanding.\" \\\n",
    "        \"\\n\\n{name} operates primarily in the {country}, trading under the ticker {ticker} on the {exchange}. As a dominant force in the {finnhubIndustry} space, the company continues to innovate and drive progress within the industry.\"\n",
    "\n",
    "    formatted_str = company_template.format(**profile)\n",
    "\n",
    "    return formatted_str\n",
    "\n",
    "\n",
    "def get_prompt_by_row(symbol, row):\n",
    "\n",
    "    start_date = row['Start Date'] if isinstance(row['Start Date'], str) else row['Start Date'].strftime('%Y-%m-%d')\n",
    "    end_date = row['End Date'] if isinstance(row['End Date'], str) else row['End Date'].strftime('%Y-%m-%d')\n",
    "    term = 'increased' if row['End Price'] > row['Start Price'] else 'decreased'\n",
    "    head = \"From {} to {}, {}'s stock price {} from {:.2f} to {:.2f}. Company news during this period are listed below:\\n\\n\".format(\n",
    "        start_date, end_date, symbol, term, row['Start Price'], row['End Price'])\n",
    "\n",
    "    news = json.loads(row[\"News\"])\n",
    "    news = [\"[Headline]: {}\\n[Summary]: {}\\n\".format(\n",
    "        n['headline'], n['summary']) for n in news if n['date'][:8] <= end_date.replace('-', '') and \\\n",
    "        not n['summary'].startswith(\"Looking for stock market analysis and research with proves results?\")]\n",
    "\n",
    "    basics = json.loads(row['Basics'])\n",
    "    if basics:\n",
    "        basics = \"Some recent basic financials of {}, reported at {}, are presented below:\\n\\n[Basic Financials]:\\n\\n\".format(\n",
    "            symbol, basics['period']) + \"\\n\".join(f\"{k}: {v}\" for k, v in basics.items() if k != 'period')\n",
    "    else:\n",
    "        basics = \"[Basic Financials]:\\n\\nNo basic financial reported.\"\n",
    "\n",
    "    return head, news, basics\n",
    "\n",
    "\n",
    "def sample_news(news, k=5):\n",
    "\n",
    "    return [news[i] for i in sorted(random.sample(range(len(news)), k))]\n",
    "\n",
    "\n",
    "def get_current_basics(symbol, curday):\n",
    "\n",
    "    basic_financials = finnhub_client.company_basic_financials(symbol, 'all')\n",
    "    if not basic_financials['series']:\n",
    "        raise gr.Error(f\"Failed to find basic financials for symbol {symbol} from finnhub!\")\n",
    "\n",
    "    final_basics, basic_list, basic_dict = [], [], defaultdict(dict)\n",
    "\n",
    "    for metric, value_list in basic_financials['series']['quarterly'].items():\n",
    "        for value in value_list:\n",
    "            basic_dict[value['period']].update({metric: value['v']})\n",
    "\n",
    "    for k, v in basic_dict.items():\n",
    "        v.update({'period': k})\n",
    "        basic_list.append(v)\n",
    "\n",
    "    basic_list.sort(key=lambda x: x['period'])\n",
    "\n",
    "    for basic in basic_list[::-1]:\n",
    "        if basic['period'] <= curday:\n",
    "            break\n",
    "\n",
    "    return basic\n",
    "\n",
    "\n",
    "def get_all_prompts_online(symbol, data, curday, profile, with_basics=True):\n",
    "\n",
    "    company_prompt = get_company_prompt(symbol, profile)\n",
    "\n",
    "    prev_rows = []\n",
    "\n",
    "    for row_idx, row in data.iterrows():\n",
    "        print(row)\n",
    "        head, news, _ = get_prompt_by_row(symbol, row)\n",
    "        prev_rows.append((head, news, None))\n",
    "\n",
    "    prompt = \"\"\n",
    "    for i in range(-len(prev_rows), 0):\n",
    "        prompt += \"\\n\" + prev_rows[i][0]\n",
    "        sampled_news = sample_news(\n",
    "            prev_rows[i][1],\n",
    "            min(5, len(prev_rows[i][1]))\n",
    "        )\n",
    "        if sampled_news:\n",
    "            prompt += \"\\n\".join(sampled_news)\n",
    "        else:\n",
    "            prompt += \"No relative news reported.\"\n",
    "\n",
    "    period = \"{} to {}\".format(curday, n_weeks_before(curday, -1))\n",
    "\n",
    "    if with_basics:\n",
    "        basics = get_current_basics(symbol, curday)\n",
    "        basics = \"Some recent basic financials of {}, reported at {}, are presented below:\\n\\n[Basic Financials]:\\n\\n\".format(\n",
    "            symbol, basics['period']) + \"\\n\".join(f\"{k}: {v}\" for k, v in basics.items() if k != 'period')\n",
    "    else:\n",
    "        basics = \"[Basic Financials]:\\n\\nNo basic financial reported.\"\n",
    "\n",
    "    info = company_prompt + '\\n' + prompt + '\\n' + basics\n",
    "    prompt = info + f\"\\n\\nBased on all the information before {curday}, let's first analyze the positive developments and potential concerns for {symbol}. Come up with 2-4 most important factors respectively and keep them concise. Most factors should be inferred from company related news. \" \\\n",
    "        f\"Then make your prediction of the {symbol} stock price movement for next week ({period}). Provide a summary analysis to support your prediction.\"\n",
    "\n",
    "    return info, prompt\n",
    "\n",
    "\n",
    "def construct_prompt(ticker, curday, n_weeks, use_basics, past_hours):\n",
    "\n",
    "    profile = finnhub_client.company_profile2(symbol=ticker)\n",
    "\n",
    "    try:\n",
    "        steps = [n_weeks_before(curday, n) for n in range(n_weeks + 1)][::-1]\n",
    "    except Exception:\n",
    "        print(f\"Invalid date {curday}!\")\n",
    "\n",
    "    data = get_stock_data(ticker, steps)\n",
    "    data = get_news_local(ticker, data, profile, past_hours) # changed\n",
    "    data['Basics'] = [json.dumps({})] * len(data)\n",
    "    # print(data)\n",
    "\n",
    "    info, prompt = get_all_prompts_online(ticker, data, curday, profile, use_basics)\n",
    "\n",
    "    prompt = B_INST + B_SYS + SYSTEM_PROMPT + E_SYS + prompt + E_INST\n",
    "    # print(prompt)\n",
    "\n",
    "    return info, prompt\n",
    "\n",
    "ssh_client = create_ssh_client()\n",
    "def predict(ticker, date, n_weeks, use_basics, past_hours):\n",
    "\n",
    "    print_gpu_utilization()\n",
    "\n",
    "    info, prompt = construct_prompt(ticker, date, n_weeks, use_basics, past_hours)\n",
    "\n",
    "    # additions:\n",
    "    # save prompt to a file\n",
    "    with open(\"./prompt.txt\", 'w', encoding='utf-8') as file:\n",
    "        file.write(prompt)\n",
    "        file.write(\"+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\")\n",
    "    remote_prompttxt_path = f'C:/Users/Mum/Documents/news_aggregation_ipynb/news/{ticker}_PROMPT_from-{date}_past_{past_hours}hours-offset-{offset}.txt'\n",
    "    append_file(ssh_client, \"./prompt.txt\", remote_prompttxt_path)\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompt, return_tensors='pt', padding=False\n",
    "    )\n",
    "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
    "\n",
    "    print(\"Inputs loaded onto devices.\")\n",
    "\n",
    "    res = model.generate(\n",
    "        **inputs, max_length=4096, do_sample=True,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        use_cache=True, streamer=streamer\n",
    "    )\n",
    "    output = tokenizer.decode(res[0], skip_special_tokens=True)\n",
    "    answer = re.sub(r'.*\\[/INST\\]\\s*', '', output, flags=re.DOTALL)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return info, answer, output, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243,
     "referenced_widgets": [
      "a2fc2f6ab81b44c6af6e4dc194228618",
      "9f414d01bca749e7a0e7bd4e1e7b7157",
      "859c65682ba24ef2814ad29e5dcbec59",
      "a0960e3dd855406fa3ec1b17aa97ce04",
      "6855fc16615d469bb64a770e628f7857",
      "1a07ddf7a54041a29230f7e54baa65ac",
      "4d98b9602e58401e90900ff7f4d5f4c7",
      "623b9e2ed7604aceaef1784ade832a43",
      "3e97eb1e1f084594bdc42d16f8ecb702",
      "2bad6c2304e14cb7ba43b059bed07235",
      "847e34d607c04a13b92388083df79dbe"
     ]
    },
    "id": "YtBwxKM6_FTq",
    "outputId": "f42e473b-5173-4e77-da6b-2ff0e3ed461e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1657b5a39284c57988c6ddd06115b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2220e3b7124965804dc18d2a3f3302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda1ef8abc0141248d98935a006bc800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2897a61bf21742de9a61c2ce434fa182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0141fb67219e484385be5278f75fdaea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c5b9923e0b461d8944c9da01245bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50e06b0a8c1434882b4e475ed5258c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/179 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9567a7daf0934696ab85bea66d6b2bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/528 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198abead8fb945f4a8f7a7c2820fd926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.bin:   0%|          | 0.00/40.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3618ae0258544aa90af68549b6f1471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8f1a3bc8434f34885af84b268f8b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5575b38749a488ebbb2e0c6a73a110f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc9f09af3734c7684c5c784566f2cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01215ad19b434c0198c597f443f731b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    'NousResearch/Llama-2-7b-chat-hf',\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    offload_folder=\"offload/\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    'FinGPT/fingpt-forecaster_dow30_llama2-7b_lora',\n",
    "    offload_folder=\"offload/\"\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'NousResearch/Llama-2-7b-chat-hf',\n",
    "    )\n",
    "\n",
    "streamer = TextStreamer(tokenizer)\n",
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a seasoned stock market analyst. Your task is to list the positive developments and potential concerns for companies based on relevant news and basic financials from the past weeks, then provide an analysis and prediction for the companies' stock price movement for the upcoming week. \" \\\n",
    "    \"Your answer format should be as follows:\\n\\n[Positive Developments]:\\n1. ...\\n\\n[Potential Concerns]:\\n1. ...\\n\\n[Prediction & Analysis]\\nPrediction: ...\\nAnalysis: ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbQPxeCRB0mn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-27_14-30\n",
      "GPU memory occupied: 13641 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_78/3285205267.py:50: FutureWarning: DatetimeIndex.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
      "  available_dates = stock_data.index.format()\n",
      "/tmp/ipykernel_78/3285205267.py:55: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  prices.append(stock_data['Close'][i])\n",
      "/tmp/ipykernel_78/3285205267.py:60: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  prices.append(stock_data['Close'][-1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "ssh_client = create_ssh_client()\n",
    "ticker = \"TSLA\"\n",
    "curdate = \"2024-02-27_14-30\"#get_curday()\n",
    "print(curdate)\n",
    "offset = 1\n",
    "past_hours = 24\n",
    "\n",
    "def extract_and_append_prediction_to_file(date, offset, past_hours, ticker):\n",
    "    # Define the pattern to search for\n",
    "    pattern = r\"(Down by \\d+-\\d+%|Up by \\d+-\\d+%)\"\n",
    "    # Find all occurrences of the pattern\n",
    "    matches = re.findall(pattern, answer)\n",
    "    # Open the file in append mode and write the matches\n",
    "    \n",
    "    file_name = f\"{ticker}_from-{date}_past_{past_hours}hours-{offset}.txt\"\n",
    "    with open(file_name, 'a', encoding='utf-8') as file:\n",
    "        for match in matches:\n",
    "            file.write(match + '\\n')\n",
    "            print(\"-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ prediction\")\n",
    "\n",
    "    remote_path = f'C:/Users/Mum/Documents/news_aggregation_ipynb/news/{ticker}_from-{date}_past_{past_hours}hours-offset-{offset}.txt'\n",
    "    append_file(ssh_client, file_name, remote_path)\n",
    "    \n",
    "def extract_and_append_reasoning_to_file(output, date, offset, past_hours, ticker):\n",
    "    # Open the file in append mode and write the matches\n",
    "    file_name = f\"{ticker}_reasoning_from-{date}_past_{past_hours}hours-offset={offset}.txt\"\n",
    "    with open(file_name, 'a', encoding='utf-8') as file:\n",
    "        file.write(output + '\\n')\n",
    "        file.write('-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\\n')\n",
    "        print(\"-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ output\")\n",
    "\n",
    "    remote_path = f'C:/Users/Mum/Documents/news_aggregation_ipynb/news/{ticker}_reasoning_from-{date}_past_{past_hours}hours-{offset}.txt'\n",
    "    append_file(ssh_client, file_name, remote_path)\n",
    "\n",
    "to_save = {\"date\": curdate, \"past_hours\": past_hours, \"offset\": offset, \"predictions\": []}\n",
    "def save_predictions(date, offset, past_hours, ticker, reasoning, prompt):\n",
    "    # Define the pattern to search for\n",
    "    pattern = r\"(Down by \\d+-\\d+%|Up by \\d+-\\d+%)\"\n",
    "    # Find all occurrences of the pattern\n",
    "    matches = re.findall(pattern, answer)\n",
    "    # Open the file in append mode and write the matches\n",
    "\n",
    "    for match in matches:\n",
    "            to_save['predictions'].append({\"prediction\": match, \"reasoning\": reasoning, \"prompt\": prompt})\n",
    "            print(\"-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ prediction\")\n",
    "\n",
    "def save_to_save():\n",
    "    file_name = f'{ticker}_news_predictions.jsonl'\n",
    "    remote_path = f'C:/Users/Mum/Documents/news_aggregation_ipynb/news/{ticker}_news_predictions.jsonl'\n",
    "    with open(file_name, 'w') as f:\n",
    "        json.dump(to_save, f)\n",
    "    append_file(ssh_client, file_name, remote_path)\n",
    "\n",
    "# Run the process 10 times\n",
    "for _ in range(10):\n",
    "    text, answer, output, prompt = predict(ticker, curdate, offset, False, past_hours)\n",
    "    # extract_and_append_prediction_to_file()\n",
    "    save_predictions(curdate, offset, past_hours, ticker, output, prompt)\n",
    "    # extract_and_append_reasoning_to_file(output, curdate, offset, past_hours, ticker)\n",
    "    count+=1\n",
    "    print(\"-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\", count)\n",
    "\n",
    "save_to_save()\n",
    "close_client(ssh_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_print_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            print(f\"Contents of {filename}:\")\n",
    "            for line in file:\n",
    "                print(line.strip())  # .strip() removes any leading/trailing whitespace, including newline characters\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found.\")\n",
    "\n",
    "# Example usage\n",
    "filename = \"TSLA_from:2024-01-24_past_days:1.txt\"\n",
    "#           TSLA_from:2023-11-9_past_days:3.txt\n",
    "read_and_print_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1a07ddf7a54041a29230f7e54baa65ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bad6c2304e14cb7ba43b059bed07235": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e97eb1e1f084594bdc42d16f8ecb702": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4d98b9602e58401e90900ff7f4d5f4c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "623b9e2ed7604aceaef1784ade832a43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6855fc16615d469bb64a770e628f7857": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "847e34d607c04a13b92388083df79dbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "859c65682ba24ef2814ad29e5dcbec59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_623b9e2ed7604aceaef1784ade832a43",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e97eb1e1f084594bdc42d16f8ecb702",
      "value": 2
     }
    },
    "9f414d01bca749e7a0e7bd4e1e7b7157": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a07ddf7a54041a29230f7e54baa65ac",
      "placeholder": "​",
      "style": "IPY_MODEL_4d98b9602e58401e90900ff7f4d5f4c7",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "a0960e3dd855406fa3ec1b17aa97ce04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bad6c2304e14cb7ba43b059bed07235",
      "placeholder": "​",
      "style": "IPY_MODEL_847e34d607c04a13b92388083df79dbe",
      "value": " 2/2 [01:07&lt;00:00, 30.92s/it]"
     }
    },
    "a2fc2f6ab81b44c6af6e4dc194228618": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f414d01bca749e7a0e7bd4e1e7b7157",
       "IPY_MODEL_859c65682ba24ef2814ad29e5dcbec59",
       "IPY_MODEL_a0960e3dd855406fa3ec1b17aa97ce04"
      ],
      "layout": "IPY_MODEL_6855fc16615d469bb64a770e628f7857"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
