{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqQCqE-c-sGc"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PskG05TlIa1W",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install yfinance --upgrade --no-cache-dir\n",
    "!pip install finnhub-python\n",
    "!pip3 install news-please\n",
    "\n",
    "!pip install torch\n",
    "!pip install peft\n",
    "!pip install -U accelerate\n",
    "!pip install transformers bitsandbytes\n",
    "!pip install pynvml\n",
    "!pip install nltk\n",
    "!pip install paramiko\n",
    "!pip install scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !find / -type f -exec du -h {} + | sort -rh | head -n 10\n",
    "!rm -rf /root/.cache/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paramiko\n",
    "from scp import SCPClient\n",
    "server = 'sshhop.hopto.org'\n",
    "port = 22\n",
    "user = 'mum'\n",
    "password = '1234'\n",
    "\n",
    "def create_ssh_client():\n",
    "    client = paramiko.SSHClient()\n",
    "    client.load_system_host_keys()\n",
    "    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    client.connect(server, port, user, password)\n",
    "    return client\n",
    "\n",
    "def upload_files(ssh_client, local_path, remote_path):\n",
    "    with SCPClient(ssh_client.get_transport()) as scp:\n",
    "        scp.put(local_path, remote_path)  # Use put for uploading\n",
    "\n",
    "def append_file(ssh_client, local_path, remote_path, temp_path=''):\n",
    "    \n",
    "        # Check if temp_path is empty\n",
    "    if not temp_path:\n",
    "        temp_path = remote_path + '.tmp'\n",
    "\n",
    "    upload_files(ssh_client, local_path, temp_path)\n",
    "\n",
    "    # Step 2: Append the content of the temporary file to the target file\n",
    "    temp_path = temp_path.replace(\"/\", \"\\\\\")\n",
    "    remote_path = remote_path.replace(\"/\", \"\\\\\")\n",
    "                                                                                        # command = f'type {temp_path} >> {remote_path} & del {temp_path}'\n",
    "    # We use 'echo.' to add a newline before appending the contents of the temp file\n",
    "    command = f'echo. >> {remote_path} & type {temp_path} >> {remote_path} & del {temp_path}'\n",
    "    stdin, stdout, stderr = ssh_client.exec_command(command)\n",
    "    exit_status = stdout.channel.recv_exit_status()  # Wait for the command to complete\n",
    "    \n",
    "    # Reading the output of the command\n",
    "    output = stdout.read().decode('utf-8')\n",
    "    error = stderr.read().decode('utf-8')\n",
    "\n",
    "    # Check if command was successful\n",
    "    if exit_status == 0:\n",
    "        print(\"Command executed successfully\")\n",
    "    else:\n",
    "        print(f\"Command failed with exit status {exit_status}\")\n",
    "\n",
    "    # Optional: Print the outputs for debugging or logging\n",
    "    if output:\n",
    "        print(\"Output:\", output)\n",
    "        \n",
    "    if error:\n",
    "        print(\"Error:\", error)\n",
    "\n",
    "    return not exit_status\n",
    "\n",
    "def download_files(ssh_client, remote_path, local_path):\n",
    "    print(\"downloading\")\n",
    "    with SCPClient(ssh_client.get_transport()) as scp:\n",
    "        scp.get(remote_path, local_path)\n",
    "    print(\"done downloading\")\n",
    "\n",
    "# Optional: Execute a command or run a script on the remote machine\n",
    "# stdin, stdout, stderr = ssh_client.exec_command('python /path/to/remote/script.py')\n",
    "# print(stdout.read().decode())  # Assuming the script has output\n",
    "\n",
    "def close_client(ssh_client):\n",
    "    # Close the SSH connection\n",
    "    ssh_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "\n",
    "def rank_sentences(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_frequencies = defaultdict(int)\n",
    "    \n",
    "    # Tokenize words and count frequencies, ignoring stopwords\n",
    "    for word in word_tokenize(text):\n",
    "        if word.lower() not in stop_words:\n",
    "            word_frequencies[word.lower()] += 1\n",
    "    \n",
    "    # Ensure word_frequencies is not empty before finding the max frequency\n",
    "    if word_frequencies:\n",
    "        max_frequency = max(word_frequencies.values())\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "    # Normalize frequencies\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] = (word_frequencies[word] / max_frequency)\n",
    "    \n",
    "    sentence_scores = defaultdict(int)\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Score sentences by summing normalized frequencies of their words\n",
    "    for sent in sentences:\n",
    "        for word in word_tokenize(sent.lower()):\n",
    "            if word in word_frequencies:\n",
    "                sentence_scores[sent] += word_frequencies[word]\n",
    "    \n",
    "    # Get top n sentences based on their scores\n",
    "    summary_sentences = heapq.nlargest(3, sentence_scores, key=sentence_scores.get)\n",
    "    return summary_sentences\n",
    "\n",
    "rank_sentences(\"test. test test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2hMNfEgCn-X"
   },
   "source": [
    "**FinForcaster App.py**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKZwbTC3W9S6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import finnhub\n",
    "import torch\n",
    "# import gradio as gr\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pynvml import *\n",
    "from peft import PeftModel\n",
    "from collections import defaultdict\n",
    "from datetime import date, datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "\n",
    "finnhub_client = finnhub.Client(api_key=\"cmr6gghr01qvmr5q06u0cmr6gghr01qvmr5q06ug\")\n",
    "\n",
    "def print_gpu_utilization():\n",
    "\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "def get_curday():\n",
    "    return datetime.today().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "\n",
    "def n_weeks_before(date_string, n):\n",
    "    # date = datetime.strptime(date_string, \"%Y-%m-%d_%H-%M\") - timedelta(days=7*n)\n",
    "    # thedate = datetime.strptime(date_string, \"%Y-%m-%d_%H-%M\") - timedelta(days=n)\n",
    "    thedate = parse(date_string) - timedelta(days=n)\n",
    "    return thedate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def n_days_before(date_string, n):\n",
    "    thedate = datetime.strptime(date_string, \"%Y-%m-%d_%H-%M\") - timedelta(days=n)\n",
    "    return thedate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def get_stock_data(stock_symbol, steps):\n",
    "\n",
    "    stock_data = yf.download(stock_symbol, steps[0], steps[-1])\n",
    "    if len(stock_data) == 0:\n",
    "        raise gr.Error(f\"Failed to download stock price data for symbol {stock_symbol} from yfinance!\")\n",
    "\n",
    "#     print(stock_data)\n",
    "\n",
    "    dates, prices = [], []\n",
    "    available_dates = stock_data.index.format()\n",
    "\n",
    "    for date in steps[:-1]:\n",
    "        for i in range(len(stock_data)):\n",
    "            if available_dates[i] >= date:\n",
    "                prices.append(stock_data['Close'][i])\n",
    "                dates.append(datetime.strptime(available_dates[i], \"%Y-%m-%d\"))\n",
    "                break\n",
    "\n",
    "    dates.append(datetime.strptime(available_dates[-1], \"%Y-%m-%d\"))\n",
    "    prices.append(stock_data['Close'][-1])\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"Start Date\": dates[:-1], \"End Date\": dates[1:],\n",
    "        \"Start Price\": prices[:-1], \"End Price\": prices[1:]\n",
    "    })\n",
    "\n",
    "from dateutil.parser import parse\n",
    "from zoneinfo import ZoneInfo\n",
    "import random\n",
    "def get_news_local(symbol, data, profile, past_hours):\n",
    "    file_path = f'{symbol}_news.jsonl'\n",
    "    def download_news():\n",
    "        ssh_client = create_ssh_client()\n",
    "        download_files(ssh_client, f'/C:/Users/mum/Documents/news_aggregation_ipynb/news/{file_path}', f'{file_path}')\n",
    "        close_client(ssh_client)   \n",
    "    download_news()\n",
    "\n",
    "    recent_news = []    \n",
    "    # Calculate 24 hours ago from now\n",
    "    twenty_four_hours_ago = datetime.now(ZoneInfo(\"UTC\")) - timedelta(hours=past_hours)\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            article = json.loads(line)\n",
    "                # raise Exception(f\"No company news found for symbol {symbol} from local!\")\n",
    "            \n",
    "            # Convert published date from the provided format\n",
    "            article_date = parse(article.get(\"published date\"))\n",
    "\n",
    "            # Check if the article's content is not None and the article is within the last 24 hours\n",
    "            if article.get('content') and article_date > twenty_four_hours_ago:\n",
    "                # print(rank_sentences(article['content'])[:2])\n",
    "                summary_sentences = ' '.join(rank_sentences(article['content'])[:2])\n",
    "                recent_news.append({\n",
    "                    \"date\": article_date.strftime('%Y-%m-%d %H:%M'),\n",
    "                    \"headline\": article.get('title'),\n",
    "                    \"summary\": summary_sentences,\n",
    "                    \"url\": article.get('url'),\n",
    "                    \"source\": article.get(article['publisher']['title'])\n",
    "                })\n",
    "                \n",
    "        if len(recent_news) == 0:\n",
    "            print(\"NO NEWS TO EVALUATE!\")\n",
    "\n",
    "    random.shuffle(recent_news)\n",
    "    news_list = []\n",
    "    news_list.append(json.dumps(recent_news))\n",
    "    data['News'] = json.dumps(recent_news)\n",
    "    \n",
    "    print(\"Number of news items: \", len(recent_news)) \n",
    "    # print(recent_news)\n",
    "    print(data['News'])\n",
    "    return data\n",
    "\n",
    "def get_news(symbol, data, profile):\n",
    "    \n",
    "    news_list = []\n",
    "    filtered_company_name = ' '.join(profile['name'].split()[:1])\n",
    "    print(profile)\n",
    "\n",
    "    for end_date, row in data.iterrows():\n",
    "        print(\"asdfghjkl\")\n",
    "        start_date = row['Start Date'].strftime('%Y-%m-%d')\n",
    "        end_date = row['End Date'].strftime('%Y-%m-%d')\n",
    "#         print(symbol, ': ', start_date, ' - ', end_date)\n",
    "        # time.sleep(1) # control qpm\n",
    "        weekly_news = finnhub_client.company_news(symbol, _from=start_date, to=end_date)\n",
    "        if len(weekly_news) == 0:\n",
    "            raise gr.Error(f\"No company news found for symbol {symbol} from finnhub!\")\n",
    "        weekly_news = [\n",
    "            {\n",
    "                \"date\": datetime.fromtimestamp(n['datetime']).strftime('%Y-%m-%d %H:%M'),\n",
    "                \"headline\": n['headline'],\n",
    "                \"summary\": n['summary'],\n",
    "                \"url\": n['url'],\n",
    "                \"source\": n['source']\n",
    "            } \n",
    "            for n in weekly_news\n",
    "            if \"zacks.com\" not in n['summary'].lower() and \n",
    "               (symbol.lower() in n['headline'].lower() or filtered_company_name.lower() in n['headline'].lower())\n",
    "        ]\n",
    "        weekly_news.sort(key=lambda x: x['date'])\n",
    "        news_list.append(json.dumps(weekly_news))\n",
    "\n",
    "    data['News'] = news_list\n",
    "    print(data['News'])\n",
    "\n",
    "    # additions:\n",
    "    total_news_count = sum(len(json.loads(weekly_news)) for weekly_news in news_list)\n",
    "    print(\"Number of news items after filtering: \", total_news_count) \n",
    "\n",
    "    # To save the news to a file, use:\n",
    "    print_or_save_news(data['News'], f\"{symbol}_news.txt\")\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_or_save_news(news_list, filename=None):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"\")\n",
    "    for news_items_str in news_list:\n",
    "        news_items = json.loads(news_items_str)  # Load the JSON string into a list of dictionaries\n",
    "        for news in news_items:\n",
    "            news_str = f\"Date: {news['date']}\\nHeadline: {news['headline']}\\nSummary: {news['summary']}\\nURL: {news['url']}\\nSource: {news['source']}\\n\\n\"\n",
    "            if filename:\n",
    "                with open(filename, 'a', encoding='utf-8') as file:\n",
    "                    file.write(news_str)\n",
    "            else:\n",
    "                print(news_str)\n",
    "\n",
    "def get_company_prompt(symbol, profile):\n",
    "\n",
    "    # profile = finnhub_client.company_profile2(symbol=symbol)\n",
    "    if not profile:\n",
    "        raise gr.Error(f\"Failed to find company profile for symbol {symbol} from finnhub!\")\n",
    "\n",
    "    company_template = \"[Company Introduction]:\\n\\n{name} is a leading entity in the {finnhubIndustry} sector. Incorporated and publicly traded since {ipo}, the company has established its reputation as one of the key players in the market. As of today, {name} has a market capitalization of {marketCapitalization:.2f} in {currency}, with {shareOutstanding:.2f} shares outstanding.\" \\\n",
    "        \"\\n\\n{name} operates primarily in the {country}, trading under the ticker {ticker} on the {exchange}. As a dominant force in the {finnhubIndustry} space, the company continues to innovate and drive progress within the industry.\"\n",
    "\n",
    "    formatted_str = company_template.format(**profile)\n",
    "\n",
    "    return formatted_str\n",
    "\n",
    "\n",
    "def get_prompt_by_row(symbol, row):\n",
    "\n",
    "    start_date = row['Start Date'] if isinstance(row['Start Date'], str) else row['Start Date'].strftime('%Y-%m-%d')\n",
    "    end_date = row['End Date'] if isinstance(row['End Date'], str) else row['End Date'].strftime('%Y-%m-%d')\n",
    "    term = 'increased' if row['End Price'] > row['Start Price'] else 'decreased'\n",
    "    head = \"From {} to {}, {}'s stock price {} from {:.2f} to {:.2f}. Company news during this period are listed below:\\n\\n\".format(\n",
    "        start_date, end_date, symbol, term, row['Start Price'], row['End Price'])\n",
    "\n",
    "    news = json.loads(row[\"News\"])\n",
    "    news = [\"[Headline]: {}\\n[Summary]: {}\\n\".format(\n",
    "        n['headline'], n['summary']) for n in news if n['date'][:8] <= end_date.replace('-', '') and \\\n",
    "        not n['summary'].startswith(\"Looking for stock market analysis and research with proves results?\")]\n",
    "\n",
    "    basics = json.loads(row['Basics'])\n",
    "    if basics:\n",
    "        basics = \"Some recent basic financials of {}, reported at {}, are presented below:\\n\\n[Basic Financials]:\\n\\n\".format(\n",
    "            symbol, basics['period']) + \"\\n\".join(f\"{k}: {v}\" for k, v in basics.items() if k != 'period')\n",
    "    else:\n",
    "        basics = \"[Basic Financials]:\\n\\nNo basic financial reported.\"\n",
    "\n",
    "    return head, news, basics\n",
    "\n",
    "\n",
    "def sample_news(news, k=5):\n",
    "\n",
    "    return [news[i] for i in sorted(random.sample(range(len(news)), k))]\n",
    "\n",
    "\n",
    "def get_current_basics(symbol, curday):\n",
    "\n",
    "    basic_financials = finnhub_client.company_basic_financials(symbol, 'all')\n",
    "    if not basic_financials['series']:\n",
    "        raise gr.Error(f\"Failed to find basic financials for symbol {symbol} from finnhub!\")\n",
    "\n",
    "    final_basics, basic_list, basic_dict = [], [], defaultdict(dict)\n",
    "\n",
    "    for metric, value_list in basic_financials['series']['quarterly'].items():\n",
    "        for value in value_list:\n",
    "            basic_dict[value['period']].update({metric: value['v']})\n",
    "\n",
    "    for k, v in basic_dict.items():\n",
    "        v.update({'period': k})\n",
    "        basic_list.append(v)\n",
    "\n",
    "    basic_list.sort(key=lambda x: x['period'])\n",
    "\n",
    "    for basic in basic_list[::-1]:\n",
    "        if basic['period'] <= curday:\n",
    "            break\n",
    "\n",
    "    return basic\n",
    "\n",
    "\n",
    "def get_all_prompts_online(symbol, data, curday, profile, with_basics=True):\n",
    "\n",
    "    company_prompt = get_company_prompt(symbol, profile)\n",
    "\n",
    "    prev_rows = []\n",
    "\n",
    "    for row_idx, row in data.iterrows():\n",
    "        print(row)\n",
    "        head, news, _ = get_prompt_by_row(symbol, row)\n",
    "        prev_rows.append((head, news, None))\n",
    "\n",
    "    prompt = \"\"\n",
    "    for i in range(-len(prev_rows), 0):\n",
    "        prompt += \"\\n\" + prev_rows[i][0]\n",
    "        sampled_news = sample_news(\n",
    "            prev_rows[i][1],\n",
    "            min(5, len(prev_rows[i][1]))\n",
    "        )\n",
    "        if sampled_news:\n",
    "            prompt += \"\\n\".join(sampled_news)\n",
    "        else:\n",
    "            prompt += \"No relative news reported.\"\n",
    "\n",
    "    period = \"{} to {}\".format(curday, n_weeks_before(curday, -1))\n",
    "\n",
    "    if with_basics:\n",
    "        basics = get_current_basics(symbol, curday)\n",
    "        basics = \"Some recent basic financials of {}, reported at {}, are presented below:\\n\\n[Basic Financials]:\\n\\n\".format(\n",
    "            symbol, basics['period']) + \"\\n\".join(f\"{k}: {v}\" for k, v in basics.items() if k != 'period')\n",
    "    else:\n",
    "        basics = \"[Basic Financials]:\\n\\nNo basic financial reported.\"\n",
    "\n",
    "    info = company_prompt + '\\n' + prompt + '\\n' + basics\n",
    "    prompt = info + f\"\\n\\nBased on all the information before {curday}, let's first analyze the positive developments and potential concerns for {symbol}. Come up with 2-4 most important factors respectively and keep them concise. Most factors should be inferred from company related news. \" \\\n",
    "        f\"Then make your prediction of the {symbol} stock price movement for next week ({period}). Provide a summary analysis to support your prediction.\"\n",
    "\n",
    "    return info, prompt\n",
    "\n",
    "\n",
    "def construct_prompt(ticker, curday, n_weeks, use_basics, past_hours):\n",
    "\n",
    "    profile = finnhub_client.company_profile2(symbol=ticker)\n",
    "\n",
    "    try:\n",
    "        steps = [n_weeks_before(curday, n) for n in range(n_weeks + 1)][::-1]\n",
    "    except Exception:\n",
    "        print(f\"Invalid date {curday}!\")\n",
    "    print(steps)\n",
    "\n",
    "    data = get_stock_data(ticker, steps)\n",
    "    data = get_news_local(ticker, data, profile, past_hours) # changed\n",
    "    data['Basics'] = [json.dumps({})] * len(data)\n",
    "    # print(data)\n",
    "\n",
    "    info, prompt = get_all_prompts_online(ticker, data, curday, profile, use_basics)\n",
    "\n",
    "    prompt = B_INST + B_SYS + SYSTEM_PROMPT + E_SYS + prompt + E_INST\n",
    "    # print(prompt)\n",
    "\n",
    "    return info, prompt\n",
    "\n",
    "ssh_client = create_ssh_client()\n",
    "def predict(ticker, date, n_weeks, use_basics, past_hours):\n",
    "\n",
    "    print_gpu_utilization()\n",
    "\n",
    "    info, prompt = construct_prompt(ticker, date, n_weeks, use_basics, past_hours)\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompt, return_tensors='pt', padding=False\n",
    "    )\n",
    "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
    "\n",
    "    print(\"Inputs loaded onto devices.\")\n",
    "\n",
    "    res = model.generate(\n",
    "        **inputs, max_length=4096, do_sample=True,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        use_cache=True, streamer=streamer\n",
    "    )\n",
    "    output = tokenizer.decode(res[0], skip_special_tokens=True)\n",
    "    answer = re.sub(r'.*\\[/INST\\]\\s*', '', output, flags=re.DOTALL)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return info, answer, output, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243,
     "referenced_widgets": [
      "a2fc2f6ab81b44c6af6e4dc194228618",
      "9f414d01bca749e7a0e7bd4e1e7b7157",
      "859c65682ba24ef2814ad29e5dcbec59",
      "a0960e3dd855406fa3ec1b17aa97ce04",
      "6855fc16615d469bb64a770e628f7857",
      "1a07ddf7a54041a29230f7e54baa65ac",
      "4d98b9602e58401e90900ff7f4d5f4c7",
      "623b9e2ed7604aceaef1784ade832a43",
      "3e97eb1e1f084594bdc42d16f8ecb702",
      "2bad6c2304e14cb7ba43b059bed07235",
      "847e34d607c04a13b92388083df79dbe"
     ]
    },
    "id": "YtBwxKM6_FTq",
    "outputId": "f42e473b-5173-4e77-da6b-2ff0e3ed461e"
   },
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    'NousResearch/Llama-2-7b-chat-hf',\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    offload_folder=\"offload/\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    'FinGPT/fingpt-forecaster_dow30_llama2-7b_lora',\n",
    "    offload_folder=\"offload/\"\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'NousResearch/Llama-2-7b-chat-hf',\n",
    "    )\n",
    "\n",
    "streamer = TextStreamer(tokenizer)\n",
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a seasoned stock market analyst. Your task is to list the positive developments and potential concerns for companies based on relevant news and basic financials from the past weeks, then provide an analysis and prediction for the companies' stock price movement for the upcoming week. \" \\\n",
    "    \"Your answer format should be as follows:\\n\\n[Positive Developments]:\\n1. ...\\n\\n[Potential Concerns]:\\n1. ...\\n\\n[Prediction & Analysis]\\nPrediction: ...\\nAnalysis: ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbQPxeCRB0mn"
   },
   "outputs": [],
   "source": [
    "print(\"starting\")\n",
    "count = 0\n",
    "ssh_client = create_ssh_client()\n",
    "ticker = \"TSLA\"\n",
    "curdate = \"2024-02-24T14:30:00Z\"#get_curday()\n",
    "print(curdate)\n",
    "offset = 1\n",
    "past_hours = 24\n",
    "\n",
    "to_save = {\"date\": curdate, \"past_hours\": past_hours, \"offset\": offset, \"predictions\": []}\n",
    "def save_predictions(date, offset, past_hours, ticker, reasoning, prompt):\n",
    "    # Define the pattern to search for\n",
    "    pattern = r\"(Down by \\d+-\\d+%|Up by \\d+-\\d+%)\"\n",
    "    # Find all occurrences of the pattern\n",
    "    matches = re.findall(pattern, answer)\n",
    "    # Open the file in append mode and write the matches\n",
    "\n",
    "    for match in matches:\n",
    "            to_save['predictions'].append({\"prediction\": match, \"reasoning\": reasoning, \"prompt\": prompt})\n",
    "            print(\"-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ prediction\")\n",
    "\n",
    "def save_to_save():\n",
    "    file_name = f'{ticker}_news_predictions.jsonl'\n",
    "    remote_path = f'C:/Users/Mum/Documents/news_aggregation_ipynb/news/{ticker}_news_predictions.jsonl'\n",
    "    with open(file_name, 'w') as f:\n",
    "        json.dump(to_save, f)\n",
    "    append_file(ssh_client, file_name, remote_path)\n",
    "\n",
    "# Run the process 10 times\n",
    "for _ in range(10):\n",
    "    text, answer, output, prompt = predict(ticker, curdate, offset, False, past_hours)\n",
    "    # extract_and_append_prediction_to_file()\n",
    "    save_predictions(curdate, offset, past_hours, ticker, output, prompt)\n",
    "    # extract_and_append_reasoning_to_file(output, curdate, offset, past_hours, ticker)\n",
    "    count+=1\n",
    "    print(\"-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\", count)\n",
    "\n",
    "save_to_save()\n",
    "close_client(ssh_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_print_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            print(f\"Contents of {filename}:\")\n",
    "            for line in file:\n",
    "                print(line.strip())  # .strip() removes any leading/trailing whitespace, including newline characters\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found.\")\n",
    "\n",
    "# Example usage\n",
    "filename = \"TSLA_from:2024-01-24_past_days:1.txt\"\n",
    "#           TSLA_from:2023-11-9_past_days:3.txt\n",
    "read_and_print_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1a07ddf7a54041a29230f7e54baa65ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bad6c2304e14cb7ba43b059bed07235": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e97eb1e1f084594bdc42d16f8ecb702": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4d98b9602e58401e90900ff7f4d5f4c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "623b9e2ed7604aceaef1784ade832a43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6855fc16615d469bb64a770e628f7857": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "847e34d607c04a13b92388083df79dbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "859c65682ba24ef2814ad29e5dcbec59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_623b9e2ed7604aceaef1784ade832a43",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e97eb1e1f084594bdc42d16f8ecb702",
      "value": 2
     }
    },
    "9f414d01bca749e7a0e7bd4e1e7b7157": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a07ddf7a54041a29230f7e54baa65ac",
      "placeholder": "​",
      "style": "IPY_MODEL_4d98b9602e58401e90900ff7f4d5f4c7",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "a0960e3dd855406fa3ec1b17aa97ce04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bad6c2304e14cb7ba43b059bed07235",
      "placeholder": "​",
      "style": "IPY_MODEL_847e34d607c04a13b92388083df79dbe",
      "value": " 2/2 [01:07&lt;00:00, 30.92s/it]"
     }
    },
    "a2fc2f6ab81b44c6af6e4dc194228618": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f414d01bca749e7a0e7bd4e1e7b7157",
       "IPY_MODEL_859c65682ba24ef2814ad29e5dcbec59",
       "IPY_MODEL_a0960e3dd855406fa3ec1b17aa97ce04"
      ],
      "layout": "IPY_MODEL_6855fc16615d469bb64a770e628f7857"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
